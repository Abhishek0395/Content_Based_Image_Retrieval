{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagory_0\n",
      "catagory_1\n",
      "catagory_2\n",
      "catagory_3\n",
      "catagory_4\n",
      "catagory_5\n",
      "catagory_6\n",
      "catagory_7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory_list = list()\n",
    "dir_path = \"dataset\"\n",
    "for root, dirs, files in os.walk(dir_path, topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append((name))\n",
    "#print(directory_list)\n",
    "for directory in directory_list:\n",
    "    print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "labels = 'labels.csv'\n",
    "labelfile = open(labels,'w')\n",
    "for i in range(len(directory_list)):\n",
    "    readpath = (dir_path+'/' + directory_list[i]+'/*jpg')\n",
    "    #print(readpath)\n",
    "    images = glob.glob(readpath)\n",
    "    for image in images:\n",
    "        labelfile.write(image+','+directory_list[i][9:len(directory_list[i])]+'\\n')\n",
    "labelfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "labels = 'labels.csv'\n",
    "shuffled_labels = 'Shuffled_labels.csv'\n",
    "\n",
    "labelfile = open(labels, \"r\")\n",
    "lines = labelfile.readlines()\n",
    "labelfile.close()\n",
    "random.shuffle(lines)\n",
    "\n",
    "shufflefile = open(shuffled_labels, \"w\")\n",
    "shufflefile.writelines(lines)\n",
    "shufflefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "#to check uniform or not \n",
    "def uniform(pattern):\n",
    "    pat= int(pattern)\n",
    "    a=0\n",
    "    b=0\n",
    "    cnt=0\n",
    "    for i in range(0,8):\n",
    "        if( i==0 ):\n",
    "            a= int(pattern/2**(7-i))\n",
    "        else:\n",
    "            b= int(pattern/2**(7-i))\n",
    "            if(b!=a):\n",
    "                cnt=cnt+1\n",
    "                a=b\n",
    "        pattern=pattern%2**(7-i)\n",
    "    if(cnt<=2):\n",
    "        return 1 #uniform hbe\n",
    "    else:\n",
    "        return 0\n",
    "items = []\n",
    "true_items = []\n",
    "for i in range(0, 256):\n",
    "    if uniform(i):\n",
    "        items.append(i)\n",
    "        true_items.append(i)\n",
    "        \n",
    "items.append(250)\n",
    "true_items.append(250)\n",
    "print(len(items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def get(image, idx, idy):\n",
    "    if idx < (len(image)) and idy < len(image[0]) and idx>=0 and idy >=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def dir(x,y,img):\n",
    "\tax=int(img[x+1,y])-int(img[x,y])\n",
    "\tay=int(img[x,y-1])-int(img[x,y])\n",
    "    \n",
    "\tif ax>=0 and ay>=0:\n",
    "\t\treturn 1\n",
    "\telif ax<0 and ay>=0:\n",
    "\t\treturn 2\n",
    "\telif ax<0 and ay<0:\n",
    "\t\treturn 3\n",
    "\telif ax>=0 and ay<0:\n",
    "\t\treturn 4\n",
    "\t\t\n",
    "def d_lbp(x,y,img):\n",
    "    t = 40\n",
    "    out=[]\n",
    "    fx=[0,-1,-1,-1,0,1,1,1]\n",
    "    fy=[1,1,0,-1,-1,-1,0,1]\n",
    "    val = int(img[x][y])\n",
    "    for i in range(0, 8):\n",
    "        n_x = x+fx[i]\n",
    "        n_y = y+fy[i]\n",
    "        val1=int(img[n_x][n_y])\n",
    "        val2 = int(img[n_x+fx[i]][n_y+fy[i]])\n",
    "        if val2>= val1+t and val1>=val+t:\n",
    "            out.append(4)\n",
    "        elif val2<val1+t and val1>val+t:\n",
    "            out.append(3)\n",
    "        elif val2>=val1+t and val1<val+t:\n",
    "            out.append(2)\n",
    "        elif val2<val1+t and val1<val+t:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return out\n",
    "\n",
    "def add_dict(dic, val):\n",
    "    if val not in dic.keys():\n",
    "        dic[250] = dic[250] +1\n",
    "    else:\n",
    "        dic[val] = dic[val] + 1\n",
    "\n",
    "def double_lbp(img, dic1, dic2, dic3, dic4):\n",
    "    fx=[0,-1,-1,-1,0,1,1,1]\n",
    "    fy=[1,1,0,-1,-1,-1,0,1]\n",
    "    for x in range(2, len(img)-2):\n",
    "        for y in range(2, len(img[x])-2):\n",
    "            value = d_lbp(x, y, img)\n",
    "            val1=0\n",
    "            val2=0\n",
    "            val3=0\n",
    "            val4=0\n",
    "            for i in range(len(value)):\n",
    "                if(value[i]==1):\n",
    "                    val1+=2**(7-i)\n",
    "                elif(value[i]==2):\n",
    "                    val2+=2**(7-i)\n",
    "                elif(value[i]==3):\n",
    "                    val3+=2**(7-i)\n",
    "                elif(value[i]==4):\n",
    "                    val4+=2**(7-i)\n",
    "            add_dict(dic1, val1)\n",
    "            add_dict(dic2, val2)\n",
    "            add_dict(dic3, val3)\n",
    "            add_dict(dic4, val4)\n",
    "    return dic1, dic2, dic3, dic4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done in 1.3670732975006104\n",
      "50 done in 35.34597992897034\n",
      "100 done in 30.923363208770752\n",
      "150 done in 28.747615814208984\n",
      "200 done in 39.798649311065674\n",
      "250 done in 40.85354518890381\n",
      "300 done in 32.067694664001465\n",
      "350 done in 36.91008114814758\n",
      "400 done in 25.774287700653076\n",
      "450 done in 26.377923727035522\n",
      "500 done in 25.740319967269897\n",
      "550 done in 26.23100972175598\n",
      "600 done in 26.293989181518555\n",
      "650 done in 27.221457719802856\n",
      "700 done in 26.842676401138306\n",
      "750 done in 25.572420358657837\n",
      "800 done in 26.60779309272766\n",
      "850 done in 26.219033002853394\n",
      "900 done in 27.338391542434692\n",
      "950 done in 34.214465379714966\n",
      "1000 done in 26.912655353546143\n",
      "1050 done in 25.785279989242554\n",
      "1100 done in 26.296988248825073\n",
      "1150 done in 25.82124423980713\n",
      "1200 done in 27.047574520111084\n",
      "1250 done in 27.009581089019775\n",
      "1300 done in 25.58339548110962\n",
      "1350 done in 26.175041675567627\n",
      "1400 done in 25.67735767364502\n",
      "1450 done in 27.86709213256836\n",
      "1500 done in 26.627801418304443\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from scipy.stats import itemfreq\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "df = pd.read_csv(shuffled_labels, header=None)\n",
    "rows = df.iterrows()\n",
    "\n",
    "X_addrs = []\n",
    "X_hist = []\n",
    "Y_hist = []\n",
    "#row = rows[0]\n",
    "j = 0\n",
    "\n",
    "\n",
    "# uncomment below this for local tetra pattern\n",
    "dic1 = {}\n",
    "dic2 = {}\n",
    "dic3 = {}\n",
    "dic4 = {}\n",
    "\n",
    "def create_dic():\n",
    "    for i in range(len(items)):\n",
    "        dic1[items[i]] = 0\n",
    "        dic2[items[i]] = 0\n",
    "        dic3[items[i]] = 0\n",
    "        dic4[items[i]] = 0\n",
    "\n",
    "start_time = time.time()      \n",
    "for row in rows:\n",
    "    #print(row[1][1])\n",
    "    create_dic()\n",
    "    img = cv2.imread(row[1][0])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    new_x = []\n",
    "    dic1, dic2, dic3, dic4 = double_lbp(img,dic1, dic2, dic3, dic4)\n",
    "    \n",
    "    x1 = []\n",
    "    for i in dic1.keys():\n",
    "        x1.append(dic1[i])\n",
    "    x1 = np.array(x1)\n",
    "    x1 = x1/np.sum(x1)\n",
    "    \n",
    "    x2 = []\n",
    "    for i in dic2.keys():\n",
    "        x2.append(dic2[i])\n",
    "    x2 = np.array(x2)\n",
    "    x2 = x2/np.sum(x2)\n",
    "    \n",
    "    x3 = []\n",
    "    for i in dic3.keys():\n",
    "        x3.append(dic3[i])\n",
    "    x3 = np.array(x3)\n",
    "    x3 = x3/np.sum(x3)\n",
    "    \n",
    "    x4 = []\n",
    "    for i in dic4.keys():\n",
    "        x4.append(dic4[i])\n",
    "    x4 = np.array(x4)\n",
    "    x4 = x4/np.sum(x4)\n",
    "    \n",
    "    new_x = x1.tolist()+x2.tolist()+x3.tolist()+x4.tolist()\n",
    "    #new_x = x1.tolist()+x2.tolist()+x4.tolist()\n",
    "    \n",
    "    X_hist.append(new_x)\n",
    "    X_addrs.append(row[1][0])\n",
    "    Y_hist.append(row[1][1])\n",
    "    if j%50==0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(str(j)+\" done in \" + str(elapsed_time))\n",
    "        start_time = time.time()\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/catagory_0\\D112_0_22.jpg\n",
      "[0.0012356919875130073, 0.0003251821019771072, 0.0005202913631633715, 0.0003902185223725286, 0.0008454734651404787, 0.0003902185223725286, 0.0001951092611862643, 0.0007804370447450572, 0.0006503642039542144, 0.0009755463059313215, 0.0007804370447450572, 6.503642039542144e-05, 0.0005202913631633715, 0.0003251821019771072, 0.00045525494276795007, 0.0009755463059313215, 0.0007154006243496358, 0.0005202913631633715, 0.0009755463059313215, 0.0020161290322580645, 0.007479188345473465, 0.006698751300728408, 0.0001951092611862643, 0.0006503642039542144, 0.0008454734651404787, 0.0013007284079084287, 0.0028616024973985433, 0.009755463059313215, 0.005072840790842872, 0.0012356919875130073, 0.0001951092611862643, 0.0007154006243496358, 0.0012356919875130073, 0.006243496357960458, 0.007088969823100937, 0.023868366285119666, 0.0003902185223725286, 0.00026014568158168577, 0.00045525494276795007, 0.0015608740894901144, 0.006113423517169615, 0.004617585848074922, 0.0006503642039542144, 0.001040582726326743, 0.007284079084287201, 0.007479188345473465, 0.03264828303850156, 0.0007804370447450572, 0.0011056191467221643, 0.005723204994797087, 0.006828824141519251, 0.008194588969823101, 0.006828824141519251, 0.024778876170655568, 0.007869406867845994, 0.005723204994797087, 0.030697190426638918, 0.5598335067637877, 0.19003642039542143, 0.669289802289282, 0.037916233090530695, 0.01177159209157128, 0.007479188345473465, 0.031867845993756506, 0.007869406867845994, 0.005072840790842872, 0.01125130072840791, 0.005463059313215401, 0.0007154006243496358, 0.0, 0.039802289281997916, 0.006633714880332987, 0.0022762747138397503, 0.00045525494276795007, 0.0, 0.012812174817898023, 0.005983350676378772, 0.0006503642039542144, 6.503642039542144e-05, 0.0, 0.0, 0.030176899063475548, 0.006698751300728408, 0.0053329864724245574, 0.0005202913631633715, 0.0, 0.0, 0.0, 0.011121227887617066, 0.008324661810613945, 0.0009755463059313215, 0.0003251821019771072, 6.503642039542144e-05, 0.0, 0.0, 0.006048387096774193, 0.002991675338189386, 0.00013007284079084288, 0.0, 6.503642039542144e-05, 0.0, 0.0005853277835587929, 6.503642039542144e-05, 0.0, 0.0, 0.0, 0.00013007284079084288, 6.503642039542144e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06900364203954214, 0.7378381893860562, 0.02217741935483871, 0.005398022892819979, 0.010731009365244537, 0.020226326742976065, 0.008259625390218522, 0.010275754422476586, 0.005072840790842872, 0.007088969823100937, 0.0009755463059313215, 0.0007804370447450572, 0.025234131113423517, 0.008519771071800209, 0.007804370447450572, 0.00026014568158168577, 0.0001951092611862643, 0.005528095733610822, 0.008064516129032258, 0.0026014568158168575, 0.0005853277835587929, 0.0, 0.0, 0.020226326742976065, 0.0076742976066597295, 0.010015608740894901, 0.0009105098855359001, 0.00013007284079084288, 0.0, 0.0, 0.003707075962539022, 0.008714880332986473, 0.0033168574401664934, 0.0011056191467221643, 0.0, 6.503642039542144e-05, 0.0, 0.007023933402705515, 0.00858480749219563, 0.0009105098855359001, 0.00013007284079084288, 0.0, 0.0, 0.0018210197710718003, 0.0007154006243496358, 0.0, 6.503642039542144e-05, 0.0, 0.0005202913631633715, 0.0003902185223725286, 0.0, 0.0, 0.0, 0.0, 0.0, 6.503642039542144e-05, 0.0, 0.0, 0.0, 0.036290322580645164, 0.9365244536940687, 0.008064516129032258, 0.005202913631633715, 0.0011706555671175858, 0.0065036420395421434, 0.0011706555671175858, 6.503642039542144e-05, 0.0035119667013527576, 0.0003902185223725286, 0.00013007284079084288, 6.503642039542144e-05, 0.007479188345473465, 0.00045525494276795007, 6.503642039542144e-05, 0.0, 0.0, 0.004422476586888657, 0.001040582726326743, 0.0, 0.0, 0.0, 0.0, 0.0057882414151925075, 0.0009755463059313215, 0.00026014568158168577, 0.0, 0.0, 0.0, 0.0, 0.004292403746097815, 0.0009105098855359001, 6.503642039542144e-05, 0.0, 0.0, 0.0, 0.0, 0.0005202913631633715, 0.00045525494276795007, 0.0, 0.0, 6.503642039542144e-05, 0.0, 0.0, 6.503642039542144e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010340790842872009]\n",
      "0\n",
      "1504\n",
      "236\n",
      "(1504, 236)\n"
     ]
    }
   ],
   "source": [
    "print(X_addrs[0])\n",
    "print(X_hist[0])\n",
    "print(Y_hist[0])\n",
    "#print(X_hist)\n",
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "print(len(X_addrs))\n",
    "print(len(X_hist[50]))\n",
    "print(X_hist.shape)\n",
    "#print((Y_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1504, 236) (1504,)\n",
      "1052\n",
      "1052\n"
     ]
    }
   ],
   "source": [
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "\n",
    "print(X_hist.shape, Y_hist.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_hist), np.array(Y_hist), test_size=0.3)\n",
    "X_train = np.array(X_train)\n",
    "print(len(X_train))\n",
    "\n",
    "'''\n",
    "for i in range(len(X_train)):\n",
    "    if(len(X_train[i]) != 26):\n",
    "       print(len(X_train[i]))\n",
    "'''\n",
    "\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1504, 236)\n",
      "1.0\n",
      "0.25\n",
      "1.0\n",
      "0.95\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "0.825\n",
      "0.725\n",
      "1.0\n",
      "0.775\n",
      "0.9\n",
      "1.0\n",
      "0.525\n",
      "1.0\n",
      "avg =  0.8849999999999998\n"
     ]
    }
   ],
   "source": [
    "#this code is to use the distance function\n",
    "def feature_distance(feature1, feature2):\n",
    "    dist = 0.0\n",
    "    for i in range(len(feature1)):\n",
    "        dist += abs((feature1[i]*1.0-feature2[i]*1.0)/(1.0+feature1[i]*1.0+feature2[i]*1.0))\n",
    "        #print(dist)\n",
    "    return dist\n",
    "x = X_hist\n",
    "print(x.shape)\n",
    "#print(unique_name[X_addrs[0]])\n",
    "#print(Y_hist[0])\n",
    "#print(Y_hist[1])\n",
    "#print(feature_distance(x[0], x[10]))\n",
    "\n",
    "#60 -> 0.\n",
    "#50->0.\n",
    "#40->0.\n",
    "#35->0.\n",
    "#30->0.\n",
    "\n",
    "\n",
    "def clc():\n",
    "    query_length = 40\n",
    "    sm = 0\n",
    "    run = 20\n",
    "    for j in range(run):\n",
    "        true_val = 0\n",
    "        false_val = 0\n",
    "        distance_list = []\n",
    "        query = x[j]\n",
    "        query_index = j\n",
    "        for i in range(len(Y_hist)):\n",
    "            distance_list.append(feature_distance(query, x[i]))\n",
    "        unsorted = zip(distance_list, Y_hist)\n",
    "        sorted_touple = sorted(unsorted, key = lambda element : element[0])\n",
    "        #print(len(sorted_touple))\n",
    "        for i in range(query_length):\n",
    "            if(sorted_touple[i][1] == Y_hist[query_index]):\n",
    "                true_val = true_val + 1\n",
    "            else:\n",
    "                #print(\"this is wrong \"+str(i)+\" confusing with \"+str(sorted_touple[i][1]))\n",
    "                false_val = false_val+1\n",
    "        sm = sm + true_val*1.0/query_length*1.0\n",
    "        print(true_val*1.0/query_length*1.0)\n",
    "    return sm/run\n",
    "print(\"avg = \", clc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85119518758904544"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = svm.SVC()\n",
    "#clf = GaussianNB()\n",
    "#clf = LogisticRegression()\n",
    "#clf = MLPClassifier(alpha=1)\n",
    "#clf = AdaBoostClassifier()\n",
    "clf = RandomForestClassifier()\n",
    "#clf = DecisionTreeClassifier()\n",
    "\n",
    "#X_train = np.array(X_train)\n",
    "print(type(X_train))\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "clf.score(X_test, Y_test)\n",
    "#0.96276595744680848\n",
    "#with threshhold 50 and 4*59 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.74618902  0.78010878  0.75596184  0.77849636  0.76778414]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85356973246794365"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#clf = pickle.load(open('RandomForest_model.sav', 'rb'))\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "scores = cross_val_score(clf,X_test,Y_test,cv=5)\n",
    "print((scores))\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85356973246794365"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#for saving model\n",
    "filename = 'my_double_lbp_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "clf = pickle.load(open('my_double_lbp_model.sav', 'rb'))\n",
    "clf.score(X_test, Y_test)\n",
    "#scores = cross_val_score(clf, X_test, Y_test, cv=20)\n",
    "#print((scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "print(type(y))\n",
    "clf.fit(X, y) \n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (26,) (14,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-b15eeeb80758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (26,) (14,) "
     ]
    }
   ],
   "source": [
    "a = [0]*26\n",
    "a = np.array(a)\n",
    "b = a.copy()\n",
    "b = [0]*14\n",
    "b = np.array(b)\n",
    "print(b.shape)\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbp-> Local derivative ternary lbp last e  tetra "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
