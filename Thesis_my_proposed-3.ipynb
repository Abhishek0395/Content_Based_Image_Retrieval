{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagory_0\n",
      "catagory_1\n",
      "catagory_2\n",
      "catagory_3\n",
      "catagory_4\n",
      "catagory_5\n",
      "catagory_6\n",
      "catagory_7\n",
      "catagory_8\n",
      "catagory_9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory_list = list()\n",
    "dir_path = \"dataset\"\n",
    "for root, dirs, files in os.walk(dir_path, topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append((name))\n",
    "#print(directory_list)\n",
    "for directory in directory_list:\n",
    "    print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "labels = 'labels.csv'\n",
    "labelfile = open(labels,'w')\n",
    "for i in range(len(directory_list)):\n",
    "    readpath = (dir_path+'/' + directory_list[i]+'/*jpg')\n",
    "    #print(readpath)\n",
    "    images = glob.glob(readpath)\n",
    "    for image in images:\n",
    "        labelfile.write(image+','+directory_list[i][9:len(directory_list[i])]+'\\n')\n",
    "labelfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "labels = 'labels.csv'\n",
    "shuffled_labels = 'Shuffled_labels.csv'\n",
    "\n",
    "labelfile = open(labels, \"r\")\n",
    "lines = labelfile.readlines()\n",
    "labelfile.close()\n",
    "random.shuffle(lines)\n",
    "\n",
    "shufflefile = open(shuffled_labels, \"w\")\n",
    "shufflefile.writelines(lines)\n",
    "shufflefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "#to check uniform or not \n",
    "def uniform(pattern):\n",
    "    pat= int(pattern)\n",
    "    a=0\n",
    "    b=0\n",
    "    cnt=0\n",
    "    for i in range(0,8):\n",
    "        if( i==0 ):\n",
    "            a= int(pattern/2**(7-i))\n",
    "        else:\n",
    "            b= int(pattern/2**(7-i))\n",
    "            if(b!=a):\n",
    "                cnt=cnt+1\n",
    "                a=b\n",
    "        pattern=pattern%2**(7-i)\n",
    "    if(cnt<=2):\n",
    "        return 1 #uniform hbe\n",
    "    else:\n",
    "        return 0\n",
    "items = []\n",
    "true_items = []\n",
    "for i in range(0, 256):\n",
    "    if uniform(i):\n",
    "        items.append(i)\n",
    "        true_items.append(i)\n",
    "        \n",
    "items.append(250)\n",
    "true_items.append(250)\n",
    "print(len(items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def get(image, idx, idy):\n",
    "    if idx < (len(image)) and idy < len(image[0]) and idx>=0 and idy >=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def dir(x,y,img):\n",
    "\tax=int(img[x+1,y])-int(img[x,y])\n",
    "\tay=int(img[x,y-1])-int(img[x,y])\n",
    "    \n",
    "\tif ax>=0 and ay>=0:\n",
    "\t\treturn 1\n",
    "\telif ax<0 and ay>=0:\n",
    "\t\treturn 2\n",
    "\telif ax<0 and ay<0:\n",
    "\t\treturn 3\n",
    "\telif ax>=0 and ay<0:\n",
    "\t\treturn 4\n",
    "\t\t\n",
    "def d_lbp(x,y,img):\n",
    "    t = 0\n",
    "    out=[]\n",
    "    fx=[0,-1,-1,-1,0,1,1,1]\n",
    "    fy=[1,1,0,-1,-1,-1,0,1]\n",
    "    val = int(img[x][y])\n",
    "    pixels = []\n",
    "    for i in range(0, 8):\n",
    "        n_x = x+fx[i]\n",
    "        n_y = y+fy[i]\n",
    "        val1=int(img[n_x][n_y])\n",
    "        pixels.append(val1-val)\n",
    "        \n",
    "    for i in range(len(pixels)):\n",
    "        if pixels[i] >= pixels[(i+1)%len(pixels)] + t:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(2)\n",
    "    return out\n",
    "\n",
    "def add_dict(dic, val):\n",
    "    if val not in dic.keys():\n",
    "        dic[250] = dic[250] +1\n",
    "    else:\n",
    "        dic[val] = dic[val] + 1\n",
    "\n",
    "def double_lbp(img, dic1, dic2):\n",
    "    fx=[0,-1,-1,-1,0,1,1,1]\n",
    "    fy=[1,1,0,-1,-1,-1,0,1]\n",
    "    for x in range(1, len(img)-1):\n",
    "        for y in range(1, len(img[x])-1):\n",
    "            value = d_lbp(x, y, img)\n",
    "            val1=0\n",
    "            val2=0\n",
    "            for i in range(len(value)):\n",
    "                if(value[i]==1):\n",
    "                    val1+=2**(7-i)\n",
    "                elif(value[i]==2):\n",
    "                    val2+=2**(7-i)\n",
    "            add_dict(dic1, val1)\n",
    "            add_dict(dic2, val2)\n",
    "    return dic1, dic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done in 0.38777756690979004\n",
      "100 done in 41.37731051445007\n",
      "200 done in 40.68672561645508\n",
      "300 done in 43.500110387802124\n",
      "400 done in 40.399906873703\n",
      "500 done in 41.305351972579956\n",
      "600 done in 42.008968114852905\n",
      "700 done in 40.5128231048584\n",
      "800 done in 42.72255992889404\n",
      "900 done in 41.030545473098755\n",
      "1000 done in 40.361910343170166\n",
      "1100 done in 43.13430404663086\n",
      "1200 done in 39.924158573150635\n",
      "1300 done in 40.12606358528137\n",
      "1400 done in 43.33520984649658\n",
      "1500 done in 40.03407835960388\n",
      "1600 done in 41.32935643196106\n",
      "1700 done in 43.78794813156128\n",
      "1800 done in 40.135040044784546\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from scipy.stats import itemfreq\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "df = pd.read_csv(shuffled_labels, header=None)\n",
    "rows = df.iterrows()\n",
    "\n",
    "X_addrs = []\n",
    "X_hist = []\n",
    "Y_hist = []\n",
    "#row = rows[0]\n",
    "j = 0\n",
    "\n",
    "\n",
    "# uncomment below this for local tetra pattern\n",
    "dic1 = {}\n",
    "dic2 = {}\n",
    "dic3 = {}\n",
    "dic4 = {}\n",
    "\n",
    "def create_dic():\n",
    "    for i in range(len(items)):\n",
    "        dic1[items[i]] = 0\n",
    "        dic2[items[i]] = 0\n",
    "        dic3[items[i]] = 0\n",
    "        dic4[items[i]] = 0\n",
    "\n",
    "start_time = time.time()      \n",
    "for row in rows:\n",
    "    #print(row[1][1])\n",
    "    create_dic()\n",
    "    img = cv2.imread(row[1][0])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    new_x = []\n",
    "    dic1, dic2 = double_lbp(img,dic1, dic2)\n",
    "    \n",
    "    x1 = []\n",
    "    for i in dic1.keys():\n",
    "        x1.append(dic1[i])\n",
    "    x1 = np.array(x1)\n",
    "    x1 = x1/np.sum(x1)\n",
    "    \n",
    "    x2 = []\n",
    "    for i in dic2.keys():\n",
    "        x2.append(dic2[i])\n",
    "    x2 = np.array(x2)\n",
    "    x2 = x2/np.sum(x2)\n",
    "    '''\n",
    "    x3 = []\n",
    "    for i in dic3.keys():\n",
    "        x3.append(dic3[i])\n",
    "    x3 = np.array(x3)\n",
    "    x3 = x3/np.sum(x3)\n",
    "    \n",
    "    x4 = []\n",
    "    for i in dic4.keys():\n",
    "        x4.append(dic4[i])\n",
    "    x4 = np.array(x4)\n",
    "    x4 = x4/np.sum(x4)\n",
    "    '''\n",
    "    #new_x = x1.tolist()+x2.tolist()+x3.tolist()+x4.tolist()\n",
    "    new_x = x1.tolist()+x2.tolist()\n",
    "    \n",
    "    X_hist.append(new_x)\n",
    "    X_addrs.append(row[1][0])\n",
    "    Y_hist.append(row[1][1])\n",
    "    if j%100==0:\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(str(j)+\" done in \" + str(elapsed_time))\n",
    "        start_time = time.time()\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/catagory_8\\D8_180_23.jpg\n",
      "[0.0, 6.298815822625347e-05, 6.298815822625347e-05, 0.0003149407911312673, 0.0, 0.000818846056941295, 0.002330561854371378, 0.0, 0.0004409171075837742, 0.002771478961955152, 0.003212396069538927, 0.0, 0.0013227513227513227, 0.003401360544217687, 0.008818342151675485, 0.0063618039808516, 0.0, 0.0001889644746787604, 0.0026455026455026454, 0.0037163013353489543, 0.0049130763416477706, 0.0011967750062988158, 0.00012597631645250694, 0.0004409171075837742, 0.0033383723859914337, 0.006739732930209121, 0.006235827664399093, 0.004220206601158982, 0.0004409171075837742, 0.0, 0.0010078105316200555, 0.0025195263290501385, 0.00799949609473419, 0.004976064499874024, 0.0037163013353489543, 0.00012597631645250694, 0.0001889644746787604, 0.0030234315948601664, 0.002708490803728899, 0.0049130763416477706, 0.0011967750062988158, 0.0004409171075837742, 0.0020786092214663643, 0.007747543461829176, 0.004787100025195263, 0.0024565381708238853, 0.0001889644746787604, 0.001889644746787604, 0.005165028974552784, 0.0010078105316200555, 6.298815822625347e-05, 0.005857898715041572, 0.002771478961955152, 0.00012597631645250694, 0.0010078105316200555, 0.0, 0.00012597631645250694, 0.0, 0.8677878558830939, 0.0, 0.00012597631645250694, 0.0, 0.0010078105316200555, 0.00012597631645250694, 0.002771478961955152, 0.005857898715041572, 6.298815822625347e-05, 0.0010078105316200555, 0.005165028974552784, 0.001889644746787604, 0.0001889644746787604, 0.0024565381708238853, 0.004787100025195263, 0.007747543461829176, 0.0020786092214663643, 0.0004409171075837742, 0.0011967750062988158, 0.0049130763416477706, 0.002708490803728899, 0.0030234315948601664, 0.0001889644746787604, 0.00012597631645250694, 0.0037163013353489543, 0.004976064499874024, 0.00799949609473419, 0.0025195263290501385, 0.0010078105316200555, 0.0, 0.0004409171075837742, 0.004220206601158982, 0.006235827664399093, 0.006739732930209121, 0.0033383723859914337, 0.0004409171075837742, 0.00012597631645250694, 0.0011967750062988158, 0.0049130763416477706, 0.0037163013353489543, 0.0026455026455026454, 0.0001889644746787604, 0.0, 0.0063618039808516, 0.008818342151675485, 0.003401360544217687, 0.0013227513227513227, 0.0, 0.003212396069538927, 0.002771478961955152, 0.0004409171075837742, 0.0, 0.002330561854371378, 0.000818846056941295, 0.0, 0.0003149407911312673, 6.298815822625347e-05, 6.298815822625347e-05, 0.0, 0.8677878558830939]\n",
      "8\n",
      "1880\n",
      "118\n",
      "(1880, 118)\n"
     ]
    }
   ],
   "source": [
    "print(X_addrs[0])\n",
    "print(X_hist[0])\n",
    "print(Y_hist[0])\n",
    "#print(X_hist)\n",
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "print(len(X_addrs))\n",
    "print(len(X_hist[50]))\n",
    "print(X_hist.shape)\n",
    "#print((Y_hist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1880, 118) (1880,)\n",
      "1316\n",
      "1316\n"
     ]
    }
   ],
   "source": [
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "\n",
    "print(X_hist.shape, Y_hist.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_hist), np.array(Y_hist), test_size=0.3)\n",
    "X_train = np.array(X_train)\n",
    "print(len(X_train))\n",
    "\n",
    "'''\n",
    "for i in range(len(X_train)):\n",
    "    if(len(X_train[i]) != 26):\n",
    "       print(len(X_train[i]))\n",
    "'''\n",
    "\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81028368794326244"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = svm.SVC()\n",
    "#clf = GaussianNB()\n",
    "#clf = LogisticRegression()\n",
    "#clf = MLPClassifier(alpha=1)\n",
    "#clf = AdaBoostClassifier()\n",
    "clf = RandomForestClassifier()\n",
    "#clf = DecisionTreeClassifier()\n",
    "\n",
    "#X_train = np.array(X_train)\n",
    "print(type(X_train))\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71551724  0.5826087   0.68695652  0.69090909  0.75925926]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8014184397163121"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#clf = pickle.load(open('RandomForest_model.sav', 'rb'))\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "scores = cross_val_score(clf,X_test,Y_test,cv=5)\n",
    "print((scores))\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014184397163121"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "#for saving model\n",
    "filename = 'my_double_lbp_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "clf = pickle.load(open('my_double_lbp_model.sav', 'rb'))\n",
    "clf.score(X_test, Y_test)\n",
    "#scores = cross_val_score(clf, X_test, Y_test, cv=20)\n",
    "#print((scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "print(type(y))\n",
    "clf.fit(X, y) \n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (26,) (14,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b15eeeb80758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (26,) (14,) "
     ]
    }
   ],
   "source": [
    "a = [0]*26\n",
    "a = np.array(a)\n",
    "b = a.copy()\n",
    "b = [0]*14\n",
    "b = np.array(b)\n",
    "print(b.shape)\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbp-> Local derivative ternary lbp last e  tetra "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
