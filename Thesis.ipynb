{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagory_0\n",
      "catagory_1\n",
      "catagory_2\n",
      "catagory_3\n",
      "catagory_4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory_list = list()\n",
    "dir_path = \"dataset\"\n",
    "for root, dirs, files in os.walk(dir_path, topdown=False):\n",
    "    for name in dirs:\n",
    "        directory_list.append((name))\n",
    "#print(directory_list)\n",
    "for directory in directory_list:\n",
    "    print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "labels = 'labels.csv'\n",
    "labelfile = open(labels,'w')\n",
    "for i in range(len(directory_list)):\n",
    "    readpath = (dir_path+'/' + directory_list[i]+'/*jpg')\n",
    "    #print(readpath)\n",
    "    images = glob.glob(readpath)\n",
    "    for image in images:\n",
    "        labelfile.write(image+','+directory_list[i][9:len(directory_list[i])]+'\\n')\n",
    "labelfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "labels = 'labels.csv'\n",
    "shuffled_labels = 'Shuffled_labels.csv'\n",
    "\n",
    "labelfile = open(labels, \"r\")\n",
    "lines = labelfile.readlines()\n",
    "labelfile.close()\n",
    "random.shuffle(lines)\n",
    "\n",
    "shufflefile = open(shuffled_labels, \"w\")\n",
    "shufflefile.writelines(lines)\n",
    "shufflefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def get(image, idx, idy):\n",
    "    if idx < (len(image)) and idy < len(image[0]) and idx>=0 and idy >=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def dir(x,y,img):\n",
    "\tax=int(img[x+1,y])-int(img[x,y])\n",
    "\tay=int(img[x,y-1])-int(img[x,y])\n",
    "    \n",
    "\tif ax>=0 and ay>=0:\n",
    "\t\treturn 1\n",
    "\telif ax<0 and ay>=0:\n",
    "\t\treturn 2\n",
    "\telif ax<0 and ay<0:\n",
    "\t\treturn 3\n",
    "\telif ax>=0 and ay<0:\n",
    "\t\treturn 4\n",
    "\t\t\n",
    "def tetra(x,y,img):\n",
    "\tout=[]\n",
    "\tfx=[0,-1,-1,-1,0,1,1,1]\n",
    "\tfy=[1,1,0,-1,-1,-1,0,1]\n",
    "\tval=dir(x,y,img)\n",
    "\tfor i in range(0, 8):\n",
    "\t\ta=dir(x+fx[i],y+fy[i],img)\n",
    "\t\t#if x==2 and y==2 :\n",
    "\t\t\t#print(val,\" \",a,\" \",x+fx[i],\"\\n\")\n",
    "\t\tif a==val:\n",
    "\t\t\tout.append(0)\n",
    "\t\telse:\n",
    "\t\t\tout.append(a)\n",
    "\treturn out,val\n",
    "\n",
    "def add_dict(dic,val1, val2, val3, val4,direc):\n",
    "    d=1\n",
    "    val=0\n",
    "    for i in range(1,5):\n",
    "        if(d!=direc):\n",
    "            if(i==1):\n",
    "                val=val1\n",
    "            elif(i==2):\n",
    "                val=val2\n",
    "            elif(i==3):\n",
    "                val=val3\n",
    "            elif(i==4):\n",
    "                val=val4\n",
    "                \n",
    "            if (1000*d+val) not in dic.keys():\n",
    "                dic[25000*d] = dic[25000*d] + 1\n",
    "            else:\n",
    "                dic[d*1000+val] = dic[d*1000+val] + 1\n",
    "        d=d+1;\n",
    "        \n",
    "def local_tetra_pattern(img, dic1, dic2, dic3, dic4):\n",
    "    for x in range(2, len(img)-2):\n",
    "        for y in range(2, len(img[0])-2):\n",
    "            value, direc = tetra(x,y,img)\n",
    "            val1=0\n",
    "            val2=0\n",
    "            val3=0\n",
    "            val4=0\n",
    "            for i in range(0,len(value)):\n",
    "                if(value[i]==1):\n",
    "                    val1+=2**(7-i)\n",
    "                elif(value[i]==2):\n",
    "                    val2+=2**(7-i)\n",
    "                elif(value[i]==3):\n",
    "                    val3+=2**(7-i)\n",
    "                elif(value[i]==4):\n",
    "                    val4+=2**(7-i)\n",
    "            dc = dir(x, y, img)\n",
    "            if dc != direc:\n",
    "                print(\"WTF = \" + str(direc) + \" \"+ str(dc))\n",
    "            \n",
    "            if direc == 1:\n",
    "                add_dict(dic1,\"NULL\",val2, val3, val4, direc)\n",
    "            if direc == 2:\n",
    "                add_dict(dic2, val1,\"NULL\",  val3, val4,  direc)\n",
    "            if direc == 3:\n",
    "                add_dict(dic3, val1, val2,\"NULL\" , val4,  direc)\n",
    "            if direc == 4:\n",
    "                add_dict(dic4, val1, val2, val3,\"NULL\",  direc)\n",
    "    return dic1, dic2, dic3, dic4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "1001\n",
      "2001\n",
      "3001\n",
      "4001\n",
      "1002\n",
      "2002\n",
      "3002\n",
      "4002\n",
      "1003\n",
      "2003\n",
      "3003\n",
      "4003\n",
      "1004\n",
      "2004\n",
      "3004\n",
      "4004\n",
      "1006\n",
      "2006\n",
      "3006\n",
      "4006\n",
      "1007\n",
      "2007\n",
      "3007\n",
      "4007\n",
      "1008\n",
      "2008\n",
      "3008\n",
      "4008\n",
      "1012\n",
      "2012\n",
      "3012\n",
      "4012\n",
      "1014\n",
      "2014\n",
      "3014\n",
      "4014\n",
      "1015\n",
      "2015\n",
      "3015\n",
      "4015\n",
      "1016\n",
      "2016\n",
      "3016\n",
      "4016\n",
      "1024\n",
      "2024\n",
      "3024\n",
      "4024\n",
      "1028\n",
      "2028\n",
      "3028\n",
      "4028\n",
      "1030\n",
      "2030\n",
      "3030\n",
      "4030\n",
      "1031\n",
      "2031\n",
      "3031\n",
      "4031\n",
      "1032\n",
      "2032\n",
      "3032\n",
      "4032\n",
      "1048\n",
      "2048\n",
      "3048\n",
      "4048\n",
      "1056\n",
      "2056\n",
      "3056\n",
      "4056\n",
      "1060\n",
      "2060\n",
      "3060\n",
      "4060\n",
      "1062\n",
      "2062\n",
      "3062\n",
      "4062\n",
      "1063\n",
      "2063\n",
      "3063\n",
      "4063\n",
      "1064\n",
      "2064\n",
      "3064\n",
      "4064\n",
      "1096\n",
      "2096\n",
      "3096\n",
      "4096\n",
      "1112\n",
      "2112\n",
      "3112\n",
      "4112\n",
      "1120\n",
      "2120\n",
      "3120\n",
      "4120\n",
      "1124\n",
      "2124\n",
      "3124\n",
      "4124\n",
      "1126\n",
      "2126\n",
      "3126\n",
      "4126\n",
      "1127\n",
      "2127\n",
      "3127\n",
      "4127\n",
      "1128\n",
      "2128\n",
      "3128\n",
      "4128\n",
      "1129\n",
      "2129\n",
      "3129\n",
      "4129\n",
      "1131\n",
      "2131\n",
      "3131\n",
      "4131\n",
      "1135\n",
      "2135\n",
      "3135\n",
      "4135\n",
      "1143\n",
      "2143\n",
      "3143\n",
      "4143\n",
      "1159\n",
      "2159\n",
      "3159\n",
      "4159\n",
      "1191\n",
      "2191\n",
      "3191\n",
      "4191\n",
      "1192\n",
      "2192\n",
      "3192\n",
      "4192\n",
      "1193\n",
      "2193\n",
      "3193\n",
      "4193\n",
      "1195\n",
      "2195\n",
      "3195\n",
      "4195\n",
      "1199\n",
      "2199\n",
      "3199\n",
      "4199\n",
      "1207\n",
      "2207\n",
      "3207\n",
      "4207\n",
      "1223\n",
      "2223\n",
      "3223\n",
      "4223\n",
      "1224\n",
      "2224\n",
      "3224\n",
      "4224\n",
      "1225\n",
      "2225\n",
      "3225\n",
      "4225\n",
      "1227\n",
      "2227\n",
      "3227\n",
      "4227\n",
      "1231\n",
      "2231\n",
      "3231\n",
      "4231\n",
      "1239\n",
      "2239\n",
      "3239\n",
      "4239\n",
      "1240\n",
      "2240\n",
      "3240\n",
      "4240\n",
      "1241\n",
      "2241\n",
      "3241\n",
      "4241\n",
      "1243\n",
      "2243\n",
      "3243\n",
      "4243\n",
      "1247\n",
      "2247\n",
      "3247\n",
      "4247\n",
      "1248\n",
      "2248\n",
      "3248\n",
      "4248\n",
      "1249\n",
      "2249\n",
      "3249\n",
      "4249\n",
      "1251\n",
      "2251\n",
      "3251\n",
      "4251\n",
      "1252\n",
      "2252\n",
      "3252\n",
      "4252\n",
      "1253\n",
      "2253\n",
      "3253\n",
      "4253\n",
      "1254\n",
      "2254\n",
      "3254\n",
      "4254\n",
      "1255\n",
      "2255\n",
      "3255\n",
      "4255\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "#to check uniform or not \n",
    "def uniform(pattern):\n",
    "    pat= int(pattern)\n",
    "    a=0\n",
    "    b=0\n",
    "    cnt=0\n",
    "    for i in range(0,8):\n",
    "        if( i==0 ):\n",
    "            a= int(pattern/2**(7-i))\n",
    "        else:\n",
    "            b= int(pattern/2**(7-i))\n",
    "            if(b!=a):\n",
    "                cnt=cnt+1\n",
    "                a=b\n",
    "        pattern=pattern%2**(7-i)\n",
    "    if(cnt<=2):\n",
    "        return 1 #uniform hbe\n",
    "    else:\n",
    "        return 0\n",
    "items = []\n",
    "true_items = []\n",
    "#items.append(0)\n",
    "for i in range(0, 256):\n",
    "    if uniform(i):\n",
    "        items.append(1*1000+i)\n",
    "        true_items.append(i)\n",
    "        items.append(2*1000+i)\n",
    "        items.append(3*1000+i)\n",
    "        items.append(4*1000+i)\n",
    "        #print(i)\n",
    "\n",
    "items.append(25000)\n",
    "true_items.append(25000)\n",
    "items.append(25000*2)\n",
    "items.append(75000)\n",
    "items.append(100000)\n",
    "print(len(items))\n",
    "for i in items:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "767\n",
      "0 done in 13.559571266174316\n",
      "767\n",
      "1 done in 10.68930983543396\n",
      "767\n",
      "2 done in 8.562358140945435\n",
      "767\n",
      "3 done in 8.725749969482422\n",
      "767\n",
      "4 done in 9.831901788711548\n",
      "767\n",
      "5 done in 8.562962770462036\n",
      "767\n",
      "6 done in 9.006126403808594\n",
      "767\n",
      "7 done in 10.18216323852539\n",
      "767\n",
      "8 done in 10.375760316848755\n",
      "767\n",
      "9 done in 12.836282968521118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d4230047842a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m#img = cv2.resize(img,(32,32))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mdic1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_tetra_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdic1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mdic_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagnitude_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdic_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m#frequency_count(img1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-acaab53fea42>\u001b[0m in \u001b[0;36mlocal_tetra_pattern\u001b[1;34m(img, dic1, dic2, dic3, dic4)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtetra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m             \u001b[0mval1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mval2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-acaab53fea42>\u001b[0m in \u001b[0;36mtetra\u001b[1;34m(x, y, img)\u001b[0m\n\u001b[0;32m     31\u001b[0m                         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from scipy.stats import itemfreq\n",
    "import time\n",
    "from functools import wraps\n",
    "\n",
    "df = pd.read_csv(shuffled_labels, header=None)\n",
    "rows = df.iterrows()\n",
    "\n",
    "X_addrs = []\n",
    "X_hist = []\n",
    "Y_hist = []\n",
    "#row = rows[0]\n",
    "j = 0\n",
    "\n",
    "# uncomment below this for local tetra pattern\n",
    "dic1 = {}\n",
    "dic2 = {}\n",
    "dic3 = {}\n",
    "dic4 = {}\n",
    "dic_m = {}\n",
    "def del_dir(dic, direct):\n",
    "    dic.pop(direct*25000, None)\n",
    "    for i in true_items:\n",
    "        dic.pop(direct*1000+i, None)\n",
    "        \n",
    "def create_dic():\n",
    "    for i in range(len(items)):\n",
    "        dic1[items[i]] = 0\n",
    "        dic2[items[i]] = 0\n",
    "        dic3[items[i]] = 0\n",
    "        dic4[items[i]] = 0\n",
    "    del_dir(dic1, 1)\n",
    "    del_dir(dic2, 2)\n",
    "    del_dir(dic3, 3)\n",
    "    del_dir(dic4, 4)\n",
    "    #print((dic1.keys()))\n",
    "        \n",
    "        \n",
    "def magnitude_pattern(img, dic_m):\n",
    "    for i in true_items:\n",
    "        dic_m[i] = 0\n",
    "    out=[]\n",
    "    fx=[0,-1,-1,-1,0,1,1,1]\n",
    "    fy=[1,1,0,-1,-1,-1,0,1]\n",
    "    for row in range(2, len(img)-2):\n",
    "        for col in range(2, len(img[0])-2):\n",
    "            for i in range(0, 8):\n",
    "                val = 0\n",
    "                centre = (int(img[row+1][col])-int(img[row][col]))**2 + (int(img[row][col-1])-int(img[row][col]))**2\n",
    "                for j in range(0, 8):\n",
    "                    new_row = row+fx[i]\n",
    "                    new_col = row+fy[i]\n",
    "                    a = (int(img[new_row+1][new_col])-int(img[new_row][new_col]))**2+(int(img[new_row][new_col-1])-int(img[new_row][new_col]))**2\n",
    "                    if centre<=a:\n",
    "                        val+=2**(7-j)\n",
    "                if val not in dic_m.keys():\n",
    "                            dic_m[250] = dic[250] +1\n",
    "                else:\n",
    "                    dic_m[val] = dic_m[val] + 1\n",
    "    return dic_m\n",
    "\n",
    "start_time = time.time()      \n",
    "for row in rows:\n",
    "    #print(row[1][1])\n",
    "    create_dic()\n",
    "    img = cv2.imread(row[1][0])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #img = cv2.resize(img,(32,32))\n",
    "    dic1, dic2, dic3, dic4 = local_tetra_pattern(img,dic1, dic2, dic3, dic4)\n",
    "    dic_m = magnitude_pattern(img, dic_m)\n",
    "    #frequency_count(img1)\n",
    "    #frequency_count(img2)\n",
    "    #frequency_count(img3)\n",
    "    #frequency_count(img4)\n",
    "    \n",
    "    new_x = []\n",
    "    \n",
    "    #change here \n",
    "    for i in dic1.keys():\n",
    "        new_x.append(dic1[i])\n",
    "    for i in dic2.keys():\n",
    "        new_x.append(dic2[i])\n",
    "    for i in dic3.keys():\n",
    "        new_x.append(dic3[i])\n",
    "    for i in dic4.keys():\n",
    "        new_x.append(dic4[i])\n",
    "    for i in dic_m.keys():\n",
    "        new_x.append(dic_m[i])\n",
    "    new_x = np.array(new_x)\n",
    "    print(len(new_x))\n",
    "    hist = new_x/np.sum(new_x)\n",
    "    #print(hist)\n",
    "    X_addrs.append(row[1][0])\n",
    "    X_hist.append(hist)\n",
    "    Y_hist.append(row[1][1])\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(str(j)+\" done in \" + str(elapsed_time))\n",
    "    start_time = time.time()\n",
    "    j = j + 1\n",
    "    \n",
    "    \n",
    "\n",
    "# uncomment up of this for local tetra pattern\n",
    "\n",
    "# uncomment below this for lbp \n",
    "'''\n",
    "for row in rows:\n",
    "    #print(row[1][1])\n",
    "    im = cv2.imread(row[1][0])\n",
    "    #print(im.shape)\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    radius = 3\n",
    "    # Number of points to be considered as neighbourers \n",
    "    no_points = 8 * radius\n",
    "    lbp = local_binary_pattern(im_gray, no_points, radius, method='uniform')\n",
    "    # Calculate the histogram\n",
    "    x = itemfreq(lbp.ravel())\n",
    "    dic = {}\n",
    "    for i in range(len(x)):\n",
    "        dic[x[i][0]] = x[i][1]\n",
    "    for i in range(26):\n",
    "        if i not in dic.keys():\n",
    "            dic[i] = 0\n",
    "    x = [[0]*2]*26\n",
    "    for i in range(26):\n",
    "        x[i][0] = i\n",
    "        x[i][1] = dic[i]\n",
    "    # Normalize the histogram\n",
    "    #print(len(x))\n",
    "    if(len(x) != 26):\n",
    "        print(x)\n",
    "    #x = np.array(x)\n",
    "    new_x = []\n",
    "    for i in range(26):\n",
    "        new_x.append(dic[i])\n",
    "    new_x = np.array(new_x)\n",
    "    hist = new_x/np.sum(new_x)\n",
    "    #hist = x[:, 1]/sum(x[:, 1])\n",
    "    # Append image path in X_name\n",
    "    X_addrs.append(row[1][0])\n",
    "    # Append histogram to X_name\n",
    "    X_hist.append(hist)\n",
    "    # Append class label in y_test\n",
    "    Y_hist.append(row[1][1])\n",
    "    if(j%100==0):\n",
    "        print(str(j)+\" done \")\n",
    "    j = j + 1\n",
    "'''\n",
    "# uncomment up of this for lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_addrs[0])\n",
    "print(X_hist[0])\n",
    "print(Y_hist[0])\n",
    "#print(X_hist)\n",
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "print(len(X_addrs))\n",
    "print(len(X_hist[50]))\n",
    "print(X_hist.shape)\n",
    "#print((Y_hist))\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.DataFrame(X_hist)\n",
    "df.to_csv(\"tetra_pattern_normalized_data_X_hist.csv\",header=None)\n",
    "df = pd.DataFrame(Y_hist)\n",
    "df.to_csv(\"tetra_pattern_normalized_label_Y_hist.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('tetra_pattern_normalized_data_X_hist.csv', sep=',',header=None)\n",
    "x = df\n",
    "Y_hist= pd.read_csv('tetra_pattern_normalized_label_Y_hist.csv', sep=',',header=None)\n",
    "Y_hist = np.array(Y_hist)\n",
    "Y_hist = Y_hist[:,1]\n",
    "X_hist = []\n",
    "x = np.array(x)\n",
    "x = x[:,1:768]\n",
    "print(len(x))\n",
    "print(Y_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (x.shape[0]):\n",
    "    #x1 = np.array(x[i])\n",
    "    x1 = np.array(x[i][0:177])\n",
    "    x1 = x1/np.sum(x1)\n",
    "    x2 = np.array(x[i][177:354])\n",
    "    x2 = x2/np.sum(x2)\n",
    "    x3 = np.array(x[i][354:531])\n",
    "    x3 = x3/np.sum(x3)\n",
    "    x4 = np.array(x[i][531:708])\n",
    "    x4 = x4/np.sum(x4)\n",
    "    x5 = np.array(x[i][708:767])\n",
    "    x5 = x5/np.sum(x5)\n",
    "    new_x = x1.tolist()+x2.tolist()+x3.tolist()+x4.tolist()+x5.tolist()\n",
    "    #new_x = np.array(new_x)\n",
    "    X_hist.append(new_x)\n",
    "    #print(new_x)\n",
    "    #print(X_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = np.array(X_hist)\n",
    "Y_hist = np.array(Y_hist)\n",
    "\n",
    "print(X_hist.shape, Y_hist.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(X_hist), np.array(Y_hist), test_size=0.3)\n",
    "X_train = np.array(X_train)\n",
    "print(len(X_train))\n",
    "\n",
    "'''\n",
    "for i in range(len(X_train)):\n",
    "    if(len(X_train[i]) != 26):\n",
    "       print(len(X_train[i]))\n",
    "'''\n",
    "\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = svm.SVC()\n",
    "#clf = GaussianNB()\n",
    "#clf = LogisticRegression()\n",
    "#clf = MLPClassifier(alpha=1)\n",
    "#clf = AdaBoostClassifier()\n",
    "clf = RandomForestClassifier()\n",
    "#clf = DecisionTreeClassifier()\n",
    "\n",
    "#X_train = np.array(X_train)\n",
    "print(type(X_train))\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#clf = pickle.load(open('RandomForest_model.sav', 'rb'))\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "scores = cross_val_score(clf,X_test,Y_test,cv=5)\n",
    "print((scores))\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-72935ca2c225>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#pickle.dump(clf, open(filename, 'wb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DecisionTree_model.sav'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#scores = cross_val_score(clf, X_test, Y_test, cv=20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#print((scores))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#for saving model\n",
    "filename = 'DecisionTree_model.sav'\n",
    "#pickle.dump(clf, open(filename, 'wb'))\n",
    "clf = pickle.load(open('DecisionTree_model.sav', 'rb'))\n",
    "clf.score(X_test, Y_test)\n",
    "#scores = cross_val_score(clf, X_test, Y_test, cv=20)\n",
    "#print((scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
    "y = np.array([1, 1, 2, 2])\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "print(type(y))\n",
    "clf.fit(X, y) \n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0]*26\n",
    "a = np.array(a)\n",
    "b = a.copy()\n",
    "b = [0]*14\n",
    "b = np.array(b)\n",
    "print(b.shape)\n",
    "c = a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lbp-> Local derivative ternary lbp last e  tetra "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
